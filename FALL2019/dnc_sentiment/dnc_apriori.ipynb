{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>blank_check</th>\n",
       "      <th>created_at</th>\n",
       "      <th>original_text</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>user_mentions</th>\n",
       "      <th>candidate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10596</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Sat Dec 07 20:25:26 +0000 2019</td>\n",
       "      <td>RT @mumbleprince: Hey #YangGang I‚Äôm living in ...</td>\n",
       "      <td>hey i ‚Äô living va extremely red county 87 dist...</td>\n",
       "      <td>Sentiment(polarity=0.08333333333333333, subjec...</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.144444</td>\n",
       "      <td>0</td>\n",
       "      <td>148</td>\n",
       "      <td>yanggang</td>\n",
       "      <td>mumbleprince</td>\n",
       "      <td>Yang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37235</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Fri Dec 06 15:39:05 +0000 2019</td>\n",
       "      <td>RT @marchandsteve: In NH, @AndrewYang continue...</td>\n",
       "      <td>in nh continues get traction amp signed lease ...</td>\n",
       "      <td>Sentiment(polarity=-0.10000000000000003, subje...</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0</td>\n",
       "      <td>129</td>\n",
       "      <td>nan</td>\n",
       "      <td>marchandsteve, AndrewYang</td>\n",
       "      <td>Yang</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       blank_check                      created_at  \\\n",
       "10596          NaN  Sat Dec 07 20:25:26 +0000 2019   \n",
       "37235          NaN  Fri Dec 06 15:39:05 +0000 2019   \n",
       "\n",
       "                                           original_text  \\\n",
       "10596  RT @mumbleprince: Hey #YangGang I‚Äôm living in ...   \n",
       "37235  RT @marchandsteve: In NH, @AndrewYang continue...   \n",
       "\n",
       "                                              clean_text  \\\n",
       "10596  hey i ‚Äô living va extremely red county 87 dist...   \n",
       "37235  in nh continues get traction amp signed lease ...   \n",
       "\n",
       "                                               sentiment  polarity  \\\n",
       "10596  Sentiment(polarity=0.08333333333333333, subjec...  0.083333   \n",
       "37235  Sentiment(polarity=-0.10000000000000003, subje... -0.100000   \n",
       "\n",
       "       subjectivity  favorite_count  retweet_count  hashtags  \\\n",
       "10596      0.144444               0            148  yanggang   \n",
       "37235      0.950000               0            129       nan   \n",
       "\n",
       "                   user_mentions candidate  \n",
       "10596               mumbleprince      Yang  \n",
       "37235  marchandsteve, AndrewYang      Yang  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from time import time\n",
    "import pprint\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "pp = pprint.PrettyPrinter(indent=4, compact=True)\n",
    "\n",
    "\n",
    "biden = pd.read_csv('biden_tweets.csv')\n",
    "biden['candidate'] = 'Biden'\n",
    "\n",
    "booker = pd.read_csv('booker_tweets.csv')\n",
    "booker['candidate'] = 'Booker'\n",
    "\n",
    "\n",
    "buttig = pd.read_csv('buttigieg_tweets.csv')\n",
    "buttig['candidate'] = 'Buttigieg'\n",
    "\n",
    "dnc = pd.read_csv('dem_deb_tweets.csv')\n",
    "dnc['candidate'] = 'DNC'\n",
    "\n",
    "gabbard = pd.read_csv('gabbard_tweets.csv')\n",
    "gabbard['candidate'] = 'Gabbard'\n",
    "\n",
    "klob = pd.read_csv('klobuchar_tweets.csv')\n",
    "klob['candidate'] = 'Klobuchar'\n",
    "\n",
    "sanders = pd.read_csv('sanders_tweets.csv')\n",
    "sanders['candidate']='Sanders'\n",
    "\n",
    "steyer = pd.read_csv('steyer_tweets.csv')\n",
    "steyer['candidate']='Steyer'\n",
    "\n",
    "warren = pd.read_csv('warren_tweets.csv')\n",
    "warren['candidate'] = 'Warren'\n",
    "\n",
    "yang = pd.read_csv('yang_tweets.csv')\n",
    "yang['candidate'] = 'Yang'\n",
    "\n",
    "\n",
    "dems = pd.concat([biden, booker, buttig, dnc, gabbard, klob, sanders, steyer, warren, yang], axis=0, sort=False)\n",
    "\n",
    "del biden, booker, buttig, dnc, gabbard, klob, sanders, steyer, warren, yang\n",
    "\n",
    "#dems.to_csv('full_dems.csv')\n",
    "\n",
    "dems.drop_duplicates()\n",
    "\n",
    "\"\"\"convert columns to strings\"\"\"\n",
    "temp_list = []\n",
    "for value in dems['clean_text']:\n",
    "    value = str(value)\n",
    "    temp_list.append(value)\n",
    "\n",
    "dems['clean_text'] = temp_list\n",
    "dems['clean_text'] = dems['clean_text'].str.lower()\n",
    "\n",
    "\n",
    "temp_list = []\n",
    "for value in dems['hashtags']:\n",
    "    value = str(value)\n",
    "    temp_list.append(value)\n",
    "    \n",
    "dems['hashtags'] = temp_list\n",
    "dems['hashtags'] = dems['hashtags'].str.lower()\n",
    "\n",
    "dems = shuffle(dems, random_state=0)\n",
    "\n",
    "dems.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try this temporarily and fuck around with this with a smaller dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_list = ['is', 'must', 'nan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index 100000\n",
      "index 200000\n",
      "index 300000\n",
      "index 400000\n",
      "index 500000\n",
      "index 600000\n",
      "index 700000\n",
      "index 800000\n",
      "index 900000\n",
      "index 1000000\n",
      "index 1100000\n",
      "index 1200000\n",
      "index 1300000\n",
      "index 1400000\n",
      "index 1500000\n",
      "index 1600000\n",
      "index 1700000\n",
      "index 1800000\n",
      "index 1900000\n",
      "index 2000000\n",
      "index 2100000\n",
      "index 2200000\n",
      "index 2300000\n",
      "index 2400000\n",
      "index 2500000\n",
      "index 2600000\n",
      "index 2700000\n",
      "index 2800000\n",
      "index 2900000\n",
      "index 3000000\n",
      "index 3100000\n",
      "13.0155\n",
      "index 100000\n",
      "index 200000\n",
      "index 300000\n",
      "index 400000\n",
      "7.1918\n",
      "the word list has 48789 words\n",
      "the tweet list has 264406 tweets\n",
      "the hashtag list has 264406 hashtags\n"
     ]
    }
   ],
   "source": [
    "word_list = []\n",
    "tweet_list = []\n",
    "hashtag_list = []\n",
    "\n",
    "\n",
    "total_index = 0\n",
    "word_index = 0\n",
    "time0 = time()\n",
    "\n",
    "for tweet in dems['clean_text']:\n",
    "    #tweet_list.append(tweet)\n",
    "    #print(tweet)\n",
    "    temp_list = tweet.split(' ')\n",
    "    attach_list = []\n",
    "    for word in temp_list:\n",
    "        if word in remove_list:\n",
    "            pass\n",
    "        else:\n",
    "            attach_list.append(word)\n",
    "    tweet_list.append(attach_list)\n",
    "    \n",
    "    for word in temp_list:\n",
    "        #word = word.lower()\n",
    "        if word in word_list:\n",
    "            total_index = total_index +1\n",
    "            pass\n",
    "        elif (len(word) <=2) or '..' in word or \"'\" in word:\n",
    "            total_index +=1\n",
    "            pass\n",
    "        else:\n",
    "            word_list.append(word)\n",
    "            total_index = total_index +1            \n",
    "            word_index = word_index+1\n",
    "        if total_index % 100000 == 0:\n",
    "            print('index {}'.format(total_index))\n",
    "time1 = time()\n",
    "print(round((time1-time0)/60, 4))\n",
    "\n",
    "\n",
    "\n",
    "total_index = 0\n",
    "word_index = 0\n",
    "time0 = time()\n",
    "\n",
    "for tweet in dems['hashtags']:\n",
    "    #tweet_list.append(tweet)\n",
    "    #print(tweet)\n",
    "    temp_list = tweet.split(' ')\n",
    "    attach_list = []\n",
    "    for word in temp_list:\n",
    "        if word in remove_list:\n",
    "            pass\n",
    "        else:\n",
    "            attach_list.append(word)\n",
    "    tweet_list.append(attach_list)\n",
    "    \n",
    "    for word in temp_list:\n",
    "        #word = word.lower()\n",
    "        if word in word_list:\n",
    "            total_index = total_index +1\n",
    "            pass\n",
    "        elif (len(word) <=2) or '..' in word or \"'\" in word:\n",
    "            total_index +=1\n",
    "            pass\n",
    "        else:\n",
    "            word_list.append(word)\n",
    "            total_index = total_index +1            \n",
    "            word_index = word_index+1\n",
    "        if total_index % 100000 == 0:\n",
    "            print('index {}'.format(total_index))\n",
    "time1 = time()\n",
    "print(round((time1-time0)/60, 4))\n",
    "print('the word list has {} words'.format(len(word_list)))\n",
    "print('the tweet list has {} tweets'.format(len(tweet_list)))\n",
    "print('the hashtag list has {} hashtags'.format(len(hashtag_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "if (4>5) or (4<5):\n",
    "    print(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "basket_list = []\n",
    "for i in range(len(tweet_list)):\n",
    "    temp_list = []\n",
    "    for word in tweet_list[i]:\n",
    "        temp_list.append(word)\n",
    "    for word in hashtag_list[i]:\n",
    "        temp_list.append(word)\n",
    "    basket_list.append(temp_list)\n",
    "    \n",
    "#pp.pprint(basket_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   [   'hey', 'i', '‚Äô', 'living', 'va', 'extremely', 'red', 'county', '87',\n",
      "        'district', 'turned', 'blue', 'first', 'time', 'in‚Ä¶', 'yanggang'],\n",
      "    [   'in', 'nh', 'continues', 'get', 'traction', 'amp', 'signed', 'lease',\n",
      "        'th', 'office', 'w/an', 'enthusiastic', 'base', 'supp‚Ä¶', 'nan'],\n",
      "    ['elizabeth', 'warren', 'bernie', 'sanders', 'warren2020'],\n",
      "    [   'so', 'hyped', 'met', 'i', 'still', 'cloud', 'motivated', 'get', 'man',\n",
      "        'office', 'like', 'never', '‚Ä¶', 'nan'],\n",
      "    [   'i', 'ran', 'one', 'doctors', 'today', 'amp', 'made', 'point', 'tell',\n",
      "        '‚Äú', 'i', 'looked', 'yang', 'guy', 'talking', 'amp', '‚Ä¶', 'nan']]\n"
     ]
    }
   ],
   "source": [
    "pp.pprint(basket_list[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try the Apriori Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.preprocessing import OnehotTransactions\n",
    "from mlxtend.frequent_patterns import apriori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\PROGRA1\\Anaconda3\\lib\\site-packages\\mlxtend\\preprocessing\\onehot.py:66: DeprecationWarning: OnehotTransactions has been deprecated and will be removed in future. Please use TransactionEncoder instead.\n",
      "  warnings.warn(msg, DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>''</th>\n",
       "      <th>'d</th>\n",
       "      <th>'father-of-the-year</th>\n",
       "      <th>'fired</th>\n",
       "      <th>'ll</th>\n",
       "      <th>'m</th>\n",
       "      <th>'medical</th>\n",
       "      <th>'policy</th>\n",
       "      <th>'re</th>\n",
       "      <th>'s</th>\n",
       "      <th>...</th>\n",
       "      <th>ü§∑‚ÄçÔ∏è</th>\n",
       "      <th>ü•Ç</th>\n",
       "      <th>ü•∞</th>\n",
       "      <th>ü•≥</th>\n",
       "      <th>ü¶Ö</th>\n",
       "      <th>üßê</th>\n",
       "      <th>üßí</th>\n",
       "      <th>üß¢</th>\n",
       "      <th>üß¢üá∫üá∏</th>\n",
       "      <th>üß¢ü§ë</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 3451 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ''     'd  'father-of-the-year  'fired    'll     'm  'medical  'policy  \\\n",
       "0  False  False                False   False  False  False     False    False   \n",
       "1  False  False                False   False  False  False     False    False   \n",
       "2  False  False                False   False  False  False     False    False   \n",
       "3  False  False                False   False  False  False     False    False   \n",
       "4  False  False                False   False  False  False     False    False   \n",
       "\n",
       "     're     's  ...    ü§∑‚ÄçÔ∏è      ü•Ç      ü•∞      ü•≥      ü¶Ö      üßê      üßí      üß¢  \\\n",
       "0  False  False  ...  False  False  False  False  False  False  False  False   \n",
       "1  False  False  ...  False  False  False  False  False  False  False  False   \n",
       "2  False  False  ...  False  False  False  False  False  False  False  False   \n",
       "3  False  False  ...  False  False  False  False  False  False  False  False   \n",
       "4  False  False  ...  False  False  False  False  False  False  False  False   \n",
       "\n",
       "     üß¢üá∫üá∏     üß¢ü§ë  \n",
       "0  False  False  \n",
       "1  False  False  \n",
       "2  False  False  \n",
       "3  False  False  \n",
       "4  False  False  \n",
       "\n",
       "[5 rows x 3451 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oht = OnehotTransactions()\n",
    "oht_array = oht.fit(basket_list).transform(basket_list)\n",
    "df = pd.DataFrame(oht_array, columns = oht.columns_)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\PROGRA1\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:1: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "# pd.Series(df.columns).to_csv('word_list.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(430461, 3)\n",
      "2 4\n"
     ]
    }
   ],
   "source": [
    "time0 = time()\n",
    "\n",
    "frequent_itemsets = apriori(df, min_support=0.01, use_colnames=True)\n",
    "frequent_itemsets['length'] = frequent_itemsets['itemsets'].apply(lambda x: len(x))\n",
    "frequent_itemsets.sort_values(by=['support', 'length'], ascending=[False, True])\n",
    "print(frequent_itemsets.shape)\n",
    "    \n",
    "time1 = time()\n",
    "print(round((time1-time0)/60), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32915, 3)\n",
      "0 4\n"
     ]
    }
   ],
   "source": [
    "time0 = time()\n",
    "\n",
    "frequent_itemsets = apriori(df, min_support=0.02, use_colnames=True)\n",
    "frequent_itemsets['length'] = frequent_itemsets['itemsets'].apply(lambda x: len(x))\n",
    "frequent_itemsets.sort_values(by=['support', 'length'], ascending=[False, True])\n",
    "print(frequent_itemsets.shape)\n",
    "    \n",
    "time1 = time()\n",
    "print(round((time1-time0)/60), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time0 = time()\n",
    "\n",
    "# frequent_itemsets = apriori(df, min_support=0.03, use_colnames=True)\n",
    "# frequent_itemsets['length'] = frequent_itemsets['itemsets'].apply(lambda x: len(x))\n",
    "# frequent_itemsets.sort_values(by=['support', 'length'], ascending=[False, True])\n",
    "# print(frequent_itemsets.shape)\n",
    "    \n",
    "# time1 = time()\n",
    "# print(round((time1-time0)/60), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.frequent_patterns import association_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rules = association_rules(frequent_itemsets, metric='confidence', min_threshold=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rules = association_rules(frequent_itemsets, metric='lift', min_threshold=1.25)\n",
    "# rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules['antecedent_length'] = rules['antecedents'].apply(lambda x: len(x)) ## apply the length function to every value of the col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antecedents</th>\n",
       "      <th>consequents</th>\n",
       "      <th>antecedent support</th>\n",
       "      <th>consequent support</th>\n",
       "      <th>support</th>\n",
       "      <th>confidence</th>\n",
       "      <th>lift</th>\n",
       "      <th>leverage</th>\n",
       "      <th>conviction</th>\n",
       "      <th>antecedent_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(biden, 's)</td>\n",
       "      <td>(nan)</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.341</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>2.346041</td>\n",
       "      <td>0.018360</td>\n",
       "      <td>3.295</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(nan, must)</td>\n",
       "      <td>(biden)</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.973684</td>\n",
       "      <td>10.358343</td>\n",
       "      <td>0.033428</td>\n",
       "      <td>34.428</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(biden, must)</td>\n",
       "      <td>(nan)</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.341</td>\n",
       "      <td>0.037</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.932551</td>\n",
       "      <td>0.024383</td>\n",
       "      <td>inf</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(watch, must)</td>\n",
       "      <td>(biden)</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.037</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.638298</td>\n",
       "      <td>0.033522</td>\n",
       "      <td>inf</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(watch, biden)</td>\n",
       "      <td>(must)</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.037</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>22.727273</td>\n",
       "      <td>0.035372</td>\n",
       "      <td>inf</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>(biden, must)</td>\n",
       "      <td>(watch)</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.037</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>24.390244</td>\n",
       "      <td>0.035483</td>\n",
       "      <td>inf</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>(nan, watch)</td>\n",
       "      <td>(biden)</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.973684</td>\n",
       "      <td>10.358343</td>\n",
       "      <td>0.033428</td>\n",
       "      <td>34.428</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>(watch, biden)</td>\n",
       "      <td>(nan)</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.341</td>\n",
       "      <td>0.037</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.932551</td>\n",
       "      <td>0.024383</td>\n",
       "      <td>inf</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>(nan, watch)</td>\n",
       "      <td>(must)</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.973684</td>\n",
       "      <td>22.129187</td>\n",
       "      <td>0.035328</td>\n",
       "      <td>36.328</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>(nan, must)</td>\n",
       "      <td>(watch)</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.973684</td>\n",
       "      <td>23.748395</td>\n",
       "      <td>0.035442</td>\n",
       "      <td>36.442</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>(watch, must)</td>\n",
       "      <td>(nan)</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.341</td>\n",
       "      <td>0.037</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.932551</td>\n",
       "      <td>0.024383</td>\n",
       "      <td>inf</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>(nan, watch, must)</td>\n",
       "      <td>(biden)</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.037</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.638298</td>\n",
       "      <td>0.033522</td>\n",
       "      <td>inf</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>(nan, watch, biden)</td>\n",
       "      <td>(must)</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.037</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>22.727273</td>\n",
       "      <td>0.035372</td>\n",
       "      <td>inf</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>(nan, biden, must)</td>\n",
       "      <td>(watch)</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.037</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>24.390244</td>\n",
       "      <td>0.035483</td>\n",
       "      <td>inf</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>(watch, must, biden)</td>\n",
       "      <td>(nan)</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.341</td>\n",
       "      <td>0.037</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.932551</td>\n",
       "      <td>0.024383</td>\n",
       "      <td>inf</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>(nan, watch)</td>\n",
       "      <td>(biden, must)</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.973684</td>\n",
       "      <td>26.315789</td>\n",
       "      <td>0.035594</td>\n",
       "      <td>36.594</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>(nan, must)</td>\n",
       "      <td>(watch, biden)</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.973684</td>\n",
       "      <td>26.315789</td>\n",
       "      <td>0.035594</td>\n",
       "      <td>36.594</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>(watch, must)</td>\n",
       "      <td>(nan, biden)</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.037</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14.084507</td>\n",
       "      <td>0.034373</td>\n",
       "      <td>inf</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>(watch, biden)</td>\n",
       "      <td>(nan, must)</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.037</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>26.315789</td>\n",
       "      <td>0.035594</td>\n",
       "      <td>inf</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>(biden, must)</td>\n",
       "      <td>(nan, watch)</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.037</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>26.315789</td>\n",
       "      <td>0.035594</td>\n",
       "      <td>inf</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             antecedents     consequents  antecedent support  \\\n",
       "14           (biden, 's)           (nan)               0.040   \n",
       "15           (nan, must)         (biden)               0.038   \n",
       "16         (biden, must)           (nan)               0.037   \n",
       "18         (watch, must)         (biden)               0.037   \n",
       "19        (watch, biden)          (must)               0.037   \n",
       "20         (biden, must)         (watch)               0.037   \n",
       "23          (nan, watch)         (biden)               0.038   \n",
       "24        (watch, biden)           (nan)               0.037   \n",
       "26          (nan, watch)          (must)               0.038   \n",
       "27           (nan, must)         (watch)               0.038   \n",
       "28         (watch, must)           (nan)               0.037   \n",
       "31    (nan, watch, must)         (biden)               0.037   \n",
       "32   (nan, watch, biden)          (must)               0.037   \n",
       "33    (nan, biden, must)         (watch)               0.037   \n",
       "34  (watch, must, biden)           (nan)               0.037   \n",
       "35          (nan, watch)   (biden, must)               0.038   \n",
       "36           (nan, must)  (watch, biden)               0.038   \n",
       "37         (watch, must)    (nan, biden)               0.037   \n",
       "38        (watch, biden)     (nan, must)               0.037   \n",
       "39         (biden, must)    (nan, watch)               0.037   \n",
       "\n",
       "    consequent support  support  confidence       lift  leverage  conviction  \\\n",
       "14               0.341    0.032    0.800000   2.346041  0.018360       3.295   \n",
       "15               0.094    0.037    0.973684  10.358343  0.033428      34.428   \n",
       "16               0.341    0.037    1.000000   2.932551  0.024383         inf   \n",
       "18               0.094    0.037    1.000000  10.638298  0.033522         inf   \n",
       "19               0.044    0.037    1.000000  22.727273  0.035372         inf   \n",
       "20               0.041    0.037    1.000000  24.390244  0.035483         inf   \n",
       "23               0.094    0.037    0.973684  10.358343  0.033428      34.428   \n",
       "24               0.341    0.037    1.000000   2.932551  0.024383         inf   \n",
       "26               0.044    0.037    0.973684  22.129187  0.035328      36.328   \n",
       "27               0.041    0.037    0.973684  23.748395  0.035442      36.442   \n",
       "28               0.341    0.037    1.000000   2.932551  0.024383         inf   \n",
       "31               0.094    0.037    1.000000  10.638298  0.033522         inf   \n",
       "32               0.044    0.037    1.000000  22.727273  0.035372         inf   \n",
       "33               0.041    0.037    1.000000  24.390244  0.035483         inf   \n",
       "34               0.341    0.037    1.000000   2.932551  0.024383         inf   \n",
       "35               0.037    0.037    0.973684  26.315789  0.035594      36.594   \n",
       "36               0.037    0.037    0.973684  26.315789  0.035594      36.594   \n",
       "37               0.071    0.037    1.000000  14.084507  0.034373         inf   \n",
       "38               0.038    0.037    1.000000  26.315789  0.035594         inf   \n",
       "39               0.038    0.037    1.000000  26.315789  0.035594         inf   \n",
       "\n",
       "    antecedent_length  \n",
       "14                  2  \n",
       "15                  2  \n",
       "16                  2  \n",
       "18                  2  \n",
       "19                  2  \n",
       "20                  2  \n",
       "23                  2  \n",
       "24                  2  \n",
       "26                  2  \n",
       "27                  2  \n",
       "28                  2  \n",
       "31                  3  \n",
       "32                  3  \n",
       "33                  3  \n",
       "34                  3  \n",
       "35                  2  \n",
       "36                  2  \n",
       "37                  2  \n",
       "38                  2  \n",
       "39                  2  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rules[(rules['antecedent_length'] >= 2) & (rules['confidence'] > 0.75) & (rules['lift'] > 1.2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 4\n"
     ]
    }
   ],
   "source": [
    "time0 = time()\n",
    "word_dic = {}\n",
    "for word in word_list:\n",
    "    word_dic[word] = []\n",
    "time1 = time()\n",
    "print(round((time1-time0)/60), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_dic['biden']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tweet Dicitonary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   'hey', 'i', '‚Äô', 'living', 'va', 'extremely', 'red', 'county', '87',\n",
      "    'district', 'turned', 'blue', 'first', 'time', 'in‚Ä¶']\n"
     ]
    }
   ],
   "source": [
    "pp.pprint(tweet_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 4\n"
     ]
    }
   ],
   "source": [
    "time0 = time()\n",
    "\n",
    "all_user_tweet_dic = {}\n",
    "\n",
    "for i in range(len(tweet_list)):\n",
    "    tweet_basket = tweet_list[i]\n",
    "    hashtag_basket = hashtag_list[i]\n",
    "\n",
    "\n",
    "    all_user_tweet_dic['user{}'.format(i)] = []\n",
    "\n",
    "    for word in tweet_basket:\n",
    "        all_user_tweet_dic['user{}'.format(i)].append(word)\n",
    "\n",
    "    for word in hashtag_basket:\n",
    "        all_user_tweet_dic['user{}'.format(i)].append(word)\n",
    "    \n",
    "time1 = time()\n",
    "print(round((time1-time0)/60), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pp.pprint(user_tweet_dic['user3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp_df = pd.DataFrame([user_tweet_dic]).T\n",
    "# temp_df.columns = ['Tweet List']\n",
    "# temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame([{'user9': 0}], index=['user9'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for user, word_basket in all_user_tweet_dic.items():\n",
    "    user_basket = all_user_tweet_dic[user]\n",
    "    for user_word in user_basket:\n",
    "        word_dic[user_word].append(1)\n",
    "        \n",
    "        \n",
    "#         for word, value in word_dic.items():\n",
    "#             if user_word in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 0\n",
    "for key, value in user_tweet_dic.items():\n",
    "    idx +=1\n",
    "    \n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx = 0\n",
    "# #while idx < 100:\n",
    "# for key, value in word_dic.items():\n",
    "#     print(key, value)\n",
    "#     idx = idx+1\n",
    "#     if idx > 40:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hashtag Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Dataframe of Elements from the Word Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hey</th>\n",
       "      <th>i</th>\n",
       "      <th>‚Äô</th>\n",
       "      <th>living</th>\n",
       "      <th>va</th>\n",
       "      <th>extremely</th>\n",
       "      <th>red</th>\n",
       "      <th>county</th>\n",
       "      <th>87</th>\n",
       "      <th>district</th>\n",
       "      <th>...</th>\n",
       "      <th>tulsiforpresident</th>\n",
       "      <th>environment,</th>\n",
       "      <th>math,</th>\n",
       "      <th>yanggangloveleaders</th>\n",
       "      <th>bidenharris,</th>\n",
       "      <th>walkawayfromdemocrats,</th>\n",
       "      <th>wwg1wga</th>\n",
       "      <th>nhpolitics,</th>\n",
       "      <th>voteforbernie,</th>\n",
       "      <th>bernieyardsign</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows √ó 3451 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   hey   i   ‚Äô  living  va  extremely  red  county  87  district  ...  \\\n",
       "0  NaN NaN NaN     NaN NaN        NaN  NaN     NaN NaN       NaN  ...   \n",
       "\n",
       "   tulsiforpresident  environment,  math,  yanggangloveleaders  bidenharris,  \\\n",
       "0                NaN           NaN    NaN                  NaN           NaN   \n",
       "\n",
       "   walkawayfromdemocrats,  wwg1wga  nhpolitics,  voteforbernie,  \\\n",
       "0                     NaN      NaN          NaN             NaN   \n",
       "\n",
       "   bernieyardsign  \n",
       "0             NaN  \n",
       "\n",
       "[1 rows x 3451 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_df = pd.DataFrame([word_dic])\n",
    "word_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-89-c58e6a9005c6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mhashtag_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhashtag_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mhashtag_set\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhash\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mhashtag_list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "hashtag_set = set()\n",
    "for value in tuple(hashtag_list):\n",
    "    hashtag_set.add(hash(value))\n",
    "\n",
    "hashtag_list\n",
    "#tweet_list = set(tweet_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tweet_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp_list = []\n",
    "# for value in dems['clean_text']:\n",
    "#     print(value)\n",
    "#     temp_list.append(value)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Metaobject: A List of Split tweet, which are themselves lists\"\"\"\n",
    "\"\"\"Basekt of tweet words, the letters in the vocabulary\"\"\"\n",
    "\"\"\"Metaobject: A lsit of hashtags, which are themselves lists\"\"\"\n",
    "\n",
    "\"\"\"Concatenate the two metaobjects\"\"\"\n",
    "\n",
    "\"\"\"for every tweet in clean_text:\n",
    "    split the tweet into a list of words\n",
    "    append the list of words to the list of tweets\n",
    "    \n",
    "    for every hashtag in hashtags:\n",
    "    split the string into a list of words\n",
    "    append the list of words to the list of tweets  \n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = set(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "contains_itself_as_a_set = True\n",
    "does_not_contain_itself_as_a_set = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(biden.shape)\n",
    "# print(booker.shape)\n",
    "# print(buttig.shape)\n",
    "# print(dnc.shape)\n",
    "# print(gabbard.shape)\n",
    "# print(klob.shape)\n",
    "# print(sanders.shape)\n",
    "# print(steyer.shape)\n",
    "# print(warren.shape)\n",
    "# print(yang.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}